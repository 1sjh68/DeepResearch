# ruff: noqa: E501
from __future__ import annotations

import hashlib
import logging
import re
import uuid
from collections.abc import Iterable, Mapping, Sequence
from dataclasses import dataclass, field
from typing import Any, cast

from config import Config
from services.vector_db import EmbeddingModel, VectorDBManager
from utils.text_processor import (
    chunk_document_for_rag,
    truncate_text_for_context_boundary_aware,
)

OutlineNode = dict[str, Any]
MetadataDict = dict[str, Any]
ChunkResult = tuple[list[str], list[MetadataDict]]


def _normalize_outline_node(mapping: Mapping[Any, Any]) -> OutlineNode:
    normalized: OutlineNode = {}
    for key, value in mapping.items():
        normalized[str(key)] = value
    return normalized


def _normalized_nodes(sequence: Sequence[Mapping[Any, Any]]) -> list[OutlineNode]:
    return [_normalize_outline_node(item) for item in sequence]


def _filter_mappings(sequence: Iterable[Any]) -> list[Mapping[Any, Any]]:
    return [item for item in sequence if isinstance(item, Mapping)]


def _normalize_metadata(mapping: Mapping[Any, Any]) -> MetadataDict:
    normalized: MetadataDict = {}
    for key, value in mapping.items():
        normalized[str(key)] = value
    return normalized


@dataclass
class RAGService:
    """è½»é‡çº§åè°ƒå™¨ï¼Œç®¡ç†å¤–éƒ¨æ•°æ®çš„å‘é‡ç´¢å¼•ã€‚"""

    config: Config
    embedding_model: EmbeddingModel | None
    _vector_manager: VectorDBManager | None = None
    _collection_name: str | None = None
    _initialized: bool = False
    _external_data_hash: str | None = None

    def _reset_index(self) -> None:
        manager = self._vector_manager
        if manager and manager.client and self._collection_name:
            try:
                manager.client.delete_collection(name=self._collection_name)
            except Exception as exc:
                logging.warning("RAGService: åˆ é™¤æ—§å‘é‡é›†åˆ '%s' å¤±è´¥: %s", self._collection_name, exc)
        self._vector_manager = None
        self._collection_name = None
        self._initialized = False
        self._external_data_hash = None

    def ensure_index(self, external_data: str) -> None:
        if not external_data or not self.embedding_model:
            return

        data_hash = hashlib.sha256(external_data.encode("utf-8")).hexdigest()

        if self._initialized:
            if data_hash == self._external_data_hash:
                logging.debug("RAGService: å¤–éƒ¨æ•°æ®æœªå˜åŒ–ï¼Œè·³è¿‡ç´¢å¼•é‡å»ºã€‚")
                return
            logging.info("RAGService: æ£€æµ‹åˆ°å¤–éƒ¨æ•°æ®å·²æ›´æ–°ï¼Œæ­£åœ¨é‡å»º RAG ç´¢å¼•ã€‚")
            self._reset_index()

        try:
            manager = VectorDBManager(self.config, self.embedding_model)
            if not manager or not manager.client:
                logging.warning("RAGService: æ— æ³•åˆå§‹åŒ–å‘é‡æ•°æ®åº“ç®¡ç†å™¨ã€‚")
                return

            session_id_part = ""
            if self.config.session_dir:
                session_id_part = self.config.session_dir.split("_")[-1]
            if not session_id_part or not session_id_part.isalnum():
                session_id_part = uuid.uuid4().hex[:8]

            doc_id: str = f"session_doc_{session_id_part}"
            chunks: list[str]
            metadatas: list[MetadataDict]
            chunks, metadatas = chunk_document_for_rag(self.config, external_data, doc_id)
            metadatas = [dict(meta) for meta in metadatas]
            if not chunks:
                logging.warning("RAGService: å¤–éƒ¨æ•°æ®æœªç”Ÿæˆæœ‰æ•ˆåˆ†å—ï¼Œè·³è¿‡ç´¢å¼•ã€‚")
                return

            collection_name: str = f"rag_{doc_id}"
            manager.collection = manager.client.get_or_create_collection(name=collection_name)
            if manager.add_experience(texts=chunks, metadatas=metadatas):
                logging.info("RAGService: RAG åˆ†å—å·²å†™å…¥é›†åˆ '%s'ã€‚", collection_name)
                self._vector_manager = manager
                self._collection_name = collection_name
                self._initialized = True
                self._external_data_hash = data_hash
            else:
                logging.warning("RAGService: RAG åˆ†å—å†™å…¥å¤±è´¥ã€‚")
        except Exception as exc:  # pragma: no cover - defensive logging
            logging.error("RAGService: åˆå§‹åŒ–ç´¢å¼•æ—¶å‘ç”Ÿé”™è¯¯: %s", exc, exc_info=True)

    def retrieve(self, query_text: str, n_results: int = 3) -> list[MetadataDict]:
        if not self._initialized or not self._vector_manager:
            return []
        try:
            raw_results: list[MetadataDict] = self._vector_manager.hybrid_retrieve_experience(query_text, n_results=n_results)
            typed_results: list[MetadataDict] = [_normalize_metadata(item) for item in raw_results]
            return typed_results
        except Exception as exc:
            logging.error("RAGService: æ£€ç´¢å¤±è´¥: %s", exc, exc_info=True)
            return []


@dataclass
class ContextRepository:
    """å­˜å‚¨ç”Ÿæˆçš„ç« èŠ‚å’Œå°èŠ‚å†…å®¹ä»¥åŠæ‘˜è¦ã€‚"""

    chapter_summaries: dict[str, str] = field(default_factory=dict)
    chapter_content: dict[str, str] = field(default_factory=dict)
    subsection_content: dict[str, dict[str, str]] = field(default_factory=dict)

    def record_chapter(self, chapter_title: str, content: str) -> None:
        self.chapter_content[chapter_title] = content

    def get_previous_chapter(self, title: str) -> str | None:
        return self.chapter_content.get(title)

    def set_summary(self, chapter_title: str, summary: str) -> None:
        self.chapter_summaries[chapter_title] = summary

    def get_summary(self, chapter_title: str) -> str | None:
        return self.chapter_summaries.get(chapter_title)


@dataclass
class ContextAssembler:
    """ä¸ºè‰ç¨¿ã€ç»­å†™å’Œè¯„å®¡å·¥ä½œæµæ„å»ºä¸Šä¸‹æ–‡åŒ…ã€‚"""

    config: Config
    outline: Mapping[str, Any]
    style_guide: str
    repository: ContextRepository
    rag_service: RAGService | None = None

    def _truncate(self, text: str, limit: int, mode: str = "tail") -> str:
        ratio = self.config.generation.prompt_budget_ratio
        return truncate_text_for_context_boundary_aware(self.config, text, int(limit * ratio), mode)

    def _rag_context(self, query_text: str, n_results: int = 3) -> str:
        if not self.rag_service:
            return ""
        results = self.rag_service.retrieve(query_text, n_results=n_results)
        if not results:
            return ""
        parts: list[str] = ["\n\n--- ä»å‚è€ƒPDFä¸­æ£€ç´¢åˆ°çš„é«˜åº¦ç›¸å…³åŸæ–‡ç‰‡æ®µ ---\\n"]
        for idx, chunk in enumerate(results, start=1):
            document_text = chunk.get("document", "å†…å®¹ç¼ºå¤±")
            parts.append(f"\n[ç›¸å…³åŸæ–‡ç‰‡æ®µ {idx}]\\n")
            parts.append(f"{document_text}\\n")
        parts.append("--- åŸæ–‡ç‰‡æ®µç»“æŸ ---\\n\n")
        return "".join(parts)

    def build_chapter_context(self, chapter_title: str) -> str:
        chapters: list[OutlineNode] = self._extract_chapters()
        chapter_obj: OutlineNode | None = None
        chapter_index = -1
        for idx, chapter in enumerate(chapters):
            if self._get_title(chapter) == chapter_title:
                chapter_obj = chapter
                chapter_index = idx
                break

        if chapter_obj is None or chapter_index == -1:
            return "[é”™è¯¯ï¼šæ— æ³•å®šä½å½“å‰ç‹¬ç«‹ç« èŠ‚ä¿¡æ¯]"

        chapter_description = self._get_description(chapter_obj) or ""
        rag_context = self._rag_context(f"{chapter_title}: {chapter_description}")
        style_guide = self.style_guide or "æ— ç‰¹å®šé£æ ¼æŒ‡å—ã€‚"

        other_titles: list[str] = []
        for chapter in chapters:
            title = self._get_title(chapter) or "æœªå‘½åç« èŠ‚"
            if title == chapter_title:
                continue
            other_titles.append(title)
        other_titles_str = "\n - ".join(other_titles) if other_titles else "æ— å…¶ä»–ç« èŠ‚ã€‚"

        prev_title = self._get_title(chapters[chapter_index - 1]) if chapter_index > 0 else None
        next_title = self._get_title(chapters[chapter_index + 1]) if chapter_index < len(chapters) - 1 else None

        prev_content = "è¿™æ˜¯æŠ¥å‘Šçš„ç¬¬ä¸€ä¸ªä¸»ç« èŠ‚ã€‚"
        if prev_title:
            prev_content_raw = self.repository.get_previous_chapter(prev_title)
            if not prev_content_raw:
                prev_content_raw = f"å‰ä¸€ä¸»ç« èŠ‚â€œ{prev_title}â€çš„å†…å®¹å°šæœªè®°å½•ã€‚"
            prev_content = self._truncate(prev_content_raw, 6000, "tail")

        next_desc = "è¿™æ˜¯æŠ¥å‘Šçš„æœ€åä¸€ä¸ªä¸»ç« èŠ‚ã€‚"
        if next_title:
            next_obj = chapters[chapter_index + 1]
            next_description = self._get_description(next_obj) or f"ä¸‹ä¸€ä¸»ç« èŠ‚â€œ{next_title}â€çš„æè¿°æœªå®šä¹‰ã€‚"
            next_desc = f"ä¸‹ä¸€ä¸»ç« èŠ‚ã€Š{next_title}ã€‹è®¡åˆ’é˜è¿°ï¼š{next_description}"

        return f"""
[æŠ¥å‘Šçš„å®Œæ•´å¤§çº²]
{self._outline_to_json()}

[é£æ ¼ä¸å£°éŸ³æŒ‡å—]
{style_guide}
{rag_context}
[å…¶ä»–ç« èŠ‚æ ‡é¢˜åˆ—è¡¨ (ä¾›ç»“æ„å‚è€ƒ)]
 - {other_titles_str}

[ã€ç« èŠ‚ N-1ã€‘ä¸Šä¸€ä¸»ç« èŠ‚ã€Š{prev_title if prev_title else "N/A"}ã€‹çš„å®Œæ•´å†…å®¹å›é¡¾]
--- å‰ä¸€ç« èŠ‚å†…å®¹å¼€å§‹ ---
{prev_content}
--- å‰ä¸€ç« èŠ‚å†…å®¹ç»“æŸ ---

[ã€ç« èŠ‚ Nã€‘å½“å‰ä¸»ç« èŠ‚ã€Š{chapter_title}ã€‹çš„æ ¸å¿ƒç›®æ ‡ä¸æè¿°]
{chapter_description or "æ— è¯¦ç»†æè¿°ã€‚"}
é‡è¦æç¤º: ä½ å°†ä¸€æ¬¡æ€§å®Œæˆæœ¬ç« èŠ‚çš„å…¨éƒ¨å†…å®¹ã€‚

[ã€ç« èŠ‚ N+1ã€‘ä¸‹ä¸€ä¸»ç« èŠ‚ã€Š{next_title if next_title else "N/A"}ã€‹çš„æ ¸å¿ƒç›®æ ‡]
{next_desc}
"""

    def build_subsection_context(self, chapter_title: str, subsection_index: int) -> str:
        chapters: list[OutlineNode] = self._extract_chapters()
        chapter_obj: OutlineNode | None = None
        chapter_index = -1
        for idx, chapter in enumerate(chapters):
            if self._get_title(chapter) == chapter_title:
                chapter_obj = chapter
                chapter_index = idx
                break

        if chapter_obj is None or chapter_index == -1:
            return "[é”™è¯¯ï¼šæ— æ³•å®šä½å½“å‰ä¸»ç« èŠ‚ä¿¡æ¯]"

        subsections: list[OutlineNode] = self._get_sections(chapter_obj)
        current_description = self._get_description(chapter_obj) or "æ— è¯¦ç»†æè¿°ã€‚"
        rag_context = ""
        if subsection_index < len(subsections):
            subsection = subsections[subsection_index]
            subsection_title = self._get_title(subsection) or ""
            subsection_desc = self._get_description(subsection) or ""
            query_text = f"{chapter_title}: {subsection_title} - {subsection_desc}"
            rag_context = self._rag_context(query_text)

        prev_chapter_title = self._get_title(chapters[chapter_index - 1]) if chapter_index > 0 else None
        prev_chapter_text = "è¿™æ˜¯æŠ¥å‘Šçš„ç¬¬ä¸€ä¸ªä¸»ç« èŠ‚ã€‚"
        if prev_chapter_title:
            prev_chapter_raw = self.repository.get_previous_chapter(prev_chapter_title)
            if not prev_chapter_raw:
                prev_chapter_raw = f"å‰ä¸€ä¸»ç« èŠ‚â€œ{prev_chapter_title}â€çš„å†…å®¹å°šæœªè®°å½•ã€‚"
            prev_chapter_text = self._truncate(prev_chapter_raw, 4000, "tail")

        accumulated_subsections: list[str] = []
        if subsection_index > 0:
            for sub_idx in range(subsection_index):
                if sub_idx < len(subsections):
                    sub_obj = subsections[sub_idx]
                    title = self._get_title(sub_obj)
                    if not title:
                        continue
                    subsection_map = self.repository.subsection_content.get(chapter_title)
                    if subsection_map:
                        content = subsection_map.get(title)
                        if content:
                            accumulated_subsections.append(f"--- å†…å®¹æ¥è‡ªï¼š{title} ---\\n{content}")
        chapter_progress_raw = "\n\n".join(accumulated_subsections) if accumulated_subsections else "è¿™æ˜¯æœ¬ç« çš„ç¬¬ä¸€ä¸ªå­ç« èŠ‚ï¼Œä¹‹å‰æ²¡æœ‰å†…å®¹ã€‚"
        chapter_progress = self._truncate(chapter_progress_raw, 4000, "tail")

        next_context = "è¿™æ˜¯æŠ¥å‘Šçš„æœ€åä¸€ä¸ªéƒ¨åˆ†ã€‚"
        if subsection_index < len(subsections) - 1:
            next_sub = subsections[subsection_index + 1]
            next_sub_title = self._get_title(next_sub) or "æœªå‘½åå­ç« èŠ‚"
            next_sub_desc = self._get_description(next_sub) or "æ— è¯¦ç»†æè¿°ã€‚"
            next_context = f"ä¸‹ä¸€ä¸ªå­ç« èŠ‚ã€Š{next_sub_title}ã€‹è®¡åˆ’é˜è¿°ï¼š{next_sub_desc}"
        elif chapter_index < len(chapters) - 1:
            next_main = chapters[chapter_index + 1]
            next_main_title = self._get_title(next_main) or "æœªå‘½åç« èŠ‚"
            next_main_desc = self._get_description(next_main) or "æ— æè¿°"
            next_context = f"å®Œæˆæœ¬ç« èŠ‚åï¼Œä¸‹ä¸€ä¸ªä¸»ç« èŠ‚æ˜¯ã€Š{next_main_title}ã€‹ï¼Œå…¶æ ¸å¿ƒç›®æ ‡æ˜¯ï¼š{next_main_desc}"

        return f"""
[æŠ¥å‘Šçš„å®Œæ•´å¤§çº²]
{self._outline_to_json()}

[é£æ ¼ä¸å£°éŸ³æŒ‡å—]
{self.style_guide or "æ— ç‰¹å®šé£æ ¼æŒ‡å—ã€‚"}
{rag_context}
[ä¸Šä¸€ä¸»ç« èŠ‚ã€Š{prev_chapter_title if prev_chapter_title else "N/A"}ã€‹çš„æ ¸å¿ƒå†…å®¹å›é¡¾]
{prev_chapter_text}

[å½“å‰ä¸»ç« èŠ‚ã€Š{chapter_title}ã€‹çš„æ ¸å¿ƒç›®æ ‡]
{current_description}

[å½“å‰ä¸»ç« èŠ‚ã€Š{chapter_title}ã€‹å·²ç”Ÿæˆçš„å°èŠ‚å†…å®¹ï¼ˆä½ æ­£åœ¨ç»­å†™ï¼‰]
{chapter_progress}

[ä¸ºåç»­å†…å®¹çš„é“ºå«ä¿¡æ¯]
{next_context}
"""

    def build_critique_context(self, chapter_title: str, full_document_text: str, section_number_map: dict[int, str] | None = None) -> str:
        chapters: list[OutlineNode] = self._extract_chapters()
        try:
            chapter_index = next(i for i, ch in enumerate(chapters) if self._get_title(ch) == chapter_title)
        except StopIteration:
            return "[é”™è¯¯ï¼šæ— æ³•å®šä½è¢«è¯„å®¡ç« èŠ‚ä¿¡æ¯]"

        prev_obj: OutlineNode | None = chapters[chapter_index - 1] if chapter_index > 0 else None
        next_obj: OutlineNode | None = chapters[chapter_index + 1] if chapter_index < len(chapters) - 1 else None

        rag_context = self._rag_context(f"Reviewing section: {chapter_title}", n_results=5)

        prev_title = self._get_title(prev_obj)
        prev_title_display = prev_title or "N/A"
        prev_content_raw: str | None
        if prev_obj and prev_title:
            prev_content_raw = self.repository.get_previous_chapter(prev_title)
            if not prev_content_raw:
                prev_content_raw = f"ç« èŠ‚ã€Š{prev_title}ã€‹çš„å†…å®¹å°šæœªè®°å½•ã€‚"
        else:
            prev_content_raw = "è¿™æ˜¯æŠ¥å‘Šçš„ç¬¬ä¸€ä¸ªä¸»ç« èŠ‚ã€‚"
        prev_content_raw_cleaned = re.sub(r"<!--\s*section_id:\s*[A-Za-z0-9-]+\s*-->", "", prev_content_raw or "")
        prev_content = self._truncate(prev_content_raw_cleaned, 6000, "middle")

        chapter_text = self._extract_chapter_text(chapter_title, full_document_text)
        # ğŸ”§ ç§»é™¤ section_id æ³¨é‡Šï¼Œé¿å… AI çœ‹åˆ° UUID
        chapter_text = re.sub(r"<!--\s*section_id:\s*[A-Za-z0-9-]+\s*-->", "", chapter_text)

        next_title = self._get_title(next_obj)
        if next_obj and next_title:
            next_summary = self.repository.get_summary(next_title)
            if not next_summary:
                next_summary = f"ç« èŠ‚ã€Š{next_title}ã€‹çš„æ‘˜è¦å°šæœªç”Ÿæˆã€‚"
        else:
            next_summary = "è¿™æ˜¯æŠ¥å‘Šçš„æœ€åä¸€ä¸ªä¸»ç« èŠ‚ã€‚"

        raw_packet = f"""
[æŠ¥å‘Šçš„å®Œæ•´å¤§çº²]
{self._outline_to_json(section_number_map)}

[é£æ ¼ä¸å£°éŸ³æŒ‡å—]
{self.style_guide or "æ— ç‰¹å®šé£æ ¼æŒ‡å—ã€‚"}
{rag_context}
[ã€ç« èŠ‚ N-1ã€‘ã€Š{prev_title_display}ã€‹çš„å…¨æ–‡å›é¡¾]
--- å†…å®¹å¼€å§‹ ---
{prev_content}
--- å†…å®¹ç»“æŸ ---

[ã€ç« èŠ‚ Nã€‘ã€Š{chapter_title}ã€‹çš„å½“å‰å…¨æ–‡ (æ­¤ä¸ºé‡ç‚¹è¯„å®¡/ä¿®æ”¹å¯¹è±¡)]
--- å†…å®¹å¼€å§‹ ---
{chapter_text}
--- å†…å®¹ç»“æŸ ---

[ã€ç« èŠ‚ N+1ã€‘ã€Š{next_title or "N/A"}ã€‹çš„æ ¸å¿ƒæ‘˜è¦]
--- å†…å®¹å¼€å§‹ ---
{next_summary}
--- å†…å®¹ç»“æŸ ---
"""
        limit = self.config.generation.max_context_for_long_text_review_tokens
        return truncate_text_for_context_boundary_aware(
            self.config,
            raw_packet,
            int(limit * self.config.generation.prompt_budget_ratio),
            "middle",
        )

    def _extract_chapters(self) -> list[OutlineNode]:
        raw_outline = self.outline.get("outline")
        if not isinstance(raw_outline, list):
            return []
        mapping_items: list[Mapping[Any, Any]] = _filter_mappings(cast(list[Any], raw_outline))
        return _normalized_nodes(mapping_items)

    @staticmethod
    def _get_sections(chapter: OutlineNode) -> list[OutlineNode]:
        sections = chapter.get("sections", [])
        if not isinstance(sections, list):
            return []
        mapping_items: list[Mapping[Any, Any]] = _filter_mappings(cast(list[Any], sections))
        return _normalized_nodes(mapping_items)

    @staticmethod
    def _get_title(node: OutlineNode | None) -> str | None:
        if not node:
            return None
        title = node.get("title")
        return title if isinstance(title, str) else None

    @staticmethod
    def _get_description(node: OutlineNode | None) -> str | None:
        if not node:
            return None
        description = node.get("description")
        return description if isinstance(description, str) else None

    def _outline_to_json(self, section_number_map: dict[int, str] | None = None) -> str:
        import json  # local import to avoid top-level dependency if unused

        def _replace_uuids_with_numbers(obj, uuid_to_number: dict[str, int]):
            """é€’å½’å°†æ‰€æœ‰UUIDæ›¿æ¢ä¸ºå¯¹åº”çš„æ•°å­—ç¼–å·"""
            if isinstance(obj, dict):
                result = {}
                for k, v in obj.items():
                    if k == "id" and isinstance(v, str) and v in uuid_to_number:
                        # å°† UUID æ›¿æ¢ä¸ºæ•°å­—ç¼–å·
                        result[k] = uuid_to_number[v]
                    else:
                        result[k] = _replace_uuids_with_numbers(v, uuid_to_number)
                return result
            elif isinstance(obj, list):
                return [_replace_uuids_with_numbers(item, uuid_to_number) for item in obj]
            return obj

        try:
            # å¦‚æœæä¾›äº†æ•°å­—æ˜ å°„è¡¨ï¼Œåˆ›å»ºåå‘æ˜ å°„ï¼ˆUUID â†’ æ•°å­—ï¼‰
            if section_number_map:
                uuid_to_number = {uuid_val: num for num, uuid_val in section_number_map.items()}
                clean_outline = _replace_uuids_with_numbers(self.outline, uuid_to_number)
            else:
                clean_outline = self.outline

            return json.dumps(clean_outline, ensure_ascii=False, indent=2)
        except TypeError:
            return str(self.outline)

    @staticmethod
    def _extract_chapter_text(chapter_title: str, full_document_text: str) -> str:
        import re

        escaped_title = re.escape(chapter_title)
        pattern = re.compile(rf"^(##\s*{escaped_title}.*?)(?=^## |\Z)", re.MULTILINE | re.DOTALL)
        match = pattern.search(full_document_text or "")
        if match:
            return match.group(1).strip()
        # ç®€åŒ–æ—¥å¿—ï¼šé™çº§åˆ° DEBUG
        logging.debug("ContextAssembler: æ— æ³•ä»æ–‡æ¡£ä¸­æå–ç« èŠ‚ '%s' çš„å†…å®¹ã€‚", chapter_title)
        return f"æœªèƒ½ä»æ–‡æ¡£ä¸­æå–ç« èŠ‚ã€Š{chapter_title}ã€‹çš„å®Œæ•´å†…å®¹ã€‚"
