"""ç”¨äºåœ¨CLIå’ŒWebå…¥å£ç‚¹è¿è¡ŒDeep Researchå·¥ä½œæµçš„å…±äº«å·¥å…·ã€‚"""

from __future__ import annotations

import logging
import os
import re
from dataclasses import dataclass
from datetime import datetime

from config import Config
from services.llm_interaction import preflight_llm_connectivity
from services.vector_db import VectorDBManager
from utils.text_processor import (
    consolidate_document_structure,
    final_post_processing,
    quality_check,
)
from workflows.graph_runner import run_graph_workflow


@dataclass
class WorkflowResult:
    """å·¥ä½œæµæ‰§è¡Œç»“æœçš„å®¹å™¨ã€‚"""

    raw_result: str
    final_answer: str | None
    quality_report: str | None
    saved_filepath: str | None
    success: bool
    error: str | None = None


def run_workflow_pipeline(
    config: Config,
    vector_db_manager: VectorDBManager | None,
    *,
    log_handler: logging.Handler | None = None,
    output_filename: str | None = None,
    save_result: bool = True,
) -> WorkflowResult:
    """æ‰§è¡Œä¸»è¦çš„ç ”ç©¶å·¥ä½œæµï¼Œå¹¶æ ¹æ®è¯·æ±‚æŒä¹…åŒ–è¾“å‡ºã€‚"""
    # é¢„æ£€ LLM è¿é€šæ€§ï¼ˆç½‘ç»œ/ä»£ç†/TLSï¼‰ï¼Œå¤±è´¥ä»…è®°å½•è­¦å‘Šï¼Œä¸é˜»æ–­æµç¨‹
    try:
        if not preflight_llm_connectivity(config):
            logging.warning("LLM è¿é€šæ€§é¢„æ£€å¤±è´¥ï¼šåç»­æ­¥éª¤å¯èƒ½å—åˆ°ç½‘ç»œå½±å“ã€‚å»ºè®®æ£€æŸ¥ç›´è¿/ä»£ç†è®¾ç½®ä¸è¶…æ—¶é‡è¯•é…ç½®ã€‚")
    except Exception as _exc:
        logging.debug("LLM è¿é€šæ€§é¢„æ£€å¼‚å¸¸: %s", _exc, exc_info=True)

    raw_result = run_graph_workflow(
        config,
        vector_db_manager,
        log_handler=log_handler,
    )

    if not raw_result or raw_result.startswith("é”™è¯¯ï¼š"):
        error_text = raw_result or "å·¥ä½œæµæœªè¿”å›ä»»ä½•ç»“æœã€‚"
        logging.error("å·¥ä½œæµæ‰§è¡Œå¤±è´¥: %s", error_text)
        return WorkflowResult(
            raw_result=raw_result,
            final_answer=None,
            quality_report=None,
            saved_filepath=None,
            success=False,
            error=error_text,
        )

    logging.info("\n--- å·¥ä½œæµå®Œæˆï¼Œæ­£åœ¨è¿›è¡Œæœ€ç»ˆçš„åå¤„ç†ã€è¯„ä¼°ä¸ä¿å­˜ ---")

    def _extract_heading_fingerprint(md_text: str) -> list[tuple[int, str, str | None]]:
        """æå–æœ‰åºçš„(level, title_text, section_id)åˆ—è¡¨ï¼Œç”¨äºç»“æ„ä¸€è‡´æ€§æ ¡éªŒã€‚"""
        if not md_text:
            return []
        heading_re = re.compile(
            r"^(#{1,6})\s+(.*?)(?:\s*<!--\s*section_id:\s*([A-Za-z0-9_-]+)\s*-->)?\s*$",
            re.MULTILINE,
        )
        result: list[tuple[int, str, str | None]] = []
        for line in md_text.splitlines():
            m = heading_re.match(line)
            if m:
                level = len(m.group(1))
                title_text = (m.group(2) or "").strip()
                section_id = m.group(3)
                result.append((level, title_text, section_id))
        return result

    before_fp = _extract_heading_fingerprint(raw_result)
    structured_answer = consolidate_document_structure(raw_result)
    after_fp = _extract_heading_fingerprint(structured_answer)

    def _filter_fingerprint(fp: list[tuple[int, str, str | None]]):
        # å¿½ç•¥æ—  section_id çš„ç« èŠ‚ï¼Œè¿™äº›ç« èŠ‚åœ¨æ•´åˆè¿‡ç¨‹ä¸­å¯èƒ½è¢«å»é‡æˆ–é‡æ’
        return [item for item in fp if item[2]]

    # å®ä¾‹çº§å¼€å…³ï¼Œè‹¥æœªé…ç½®åˆ™é»˜è®¤å¼€å¯
    strict_enforce = getattr(config, "STRICT_STRUCTURE_ENFORCEMENT", True)
    fallback_on_mismatch = getattr(config, "FINAL_FALLBACK_ON_MISMATCH", True)

    use_fallback = False
    fallback_content: str | None = None
    if strict_enforce:
        before_filtered = _filter_fingerprint(before_fp)
        after_filtered = _filter_fingerprint(after_fp)
        if before_filtered != after_filtered:
            logging.warning("ç»“æ„å¥åº·æ£€æŸ¥å¤±è´¥ï¼šåˆå¹¶åæ ‡é¢˜/ID åˆ—è¡¨ä¸åˆå¹¶å‰ä¸ä¸€è‡´ã€‚")
            logging.warning("  - åˆå¹¶å‰: %s", before_filtered)
            logging.warning("  - åˆå¹¶å: %s", after_filtered)
            if fallback_on_mismatch:
                # ä¼˜å…ˆå›é€€åˆ°æœ€è¿‘çš„ refine å¿«ç…§
                latest_refine_path = None
                session_dir = config.session_dir
                try:
                    if session_dir and os.path.isdir(session_dir):
                        iter_dir = os.path.join(session_dir, "iterations")
                        if os.path.isdir(iter_dir):
                            candidates = [os.path.join(iter_dir, fn) for fn in os.listdir(iter_dir) if fn.startswith("iter_") and "_refine" in fn and fn.endswith(".md")]
                            if candidates:

                                def _candidate_key(path: str) -> tuple[int, float]:
                                    name = os.path.basename(path)
                                    match = re.search(r"iter_(\d+)", name)
                                    iter_index = int(match.group(1)) if match else -1
                                    try:
                                        mtime = os.path.getmtime(path)
                                    except OSError:
                                        mtime = 0.0
                                    return iter_index, mtime

                                latest_refine_path = max(candidates, key=_candidate_key)
                except Exception as _e:
                    logging.warning("æ‰«æ refine å¿«ç…§å¤±è´¥: %s", _e)

                if latest_refine_path and os.path.isfile(latest_refine_path):
                    try:
                        with open(latest_refine_path, encoding="utf-8") as rf:
                            fallback_content = rf.read()
                        logging.info("å›é€€åˆ°æœ€æ–° refine å¿«ç…§: %s", latest_refine_path)
                    except Exception as _e:
                        logging.warning("è¯»å– refine å¿«ç…§å¤±è´¥ï¼Œå°†å›é€€åˆ°åˆå¹¶å‰çš„æŠ›å…‰æ–‡æœ¬: %s", _e)
                        fallback_content = raw_result
                else:
                    fallback_content = raw_result
                use_fallback = True

    final_answer = final_post_processing(fallback_content if use_fallback and fallback_content else structured_answer)

    quality_report = None
    if config.workflow.disable_final_quality_check:
        logging.info("\n--- å·²ç¦ç”¨æœ€ç»ˆè´¨é‡è¯„ä¼° (DISABLE_FINAL_QUALITY_CHECK=true) ---")
    else:
        logging.info("\n--- æœ€ç»ˆäº§å‡ºè´¨é‡è¯„ä¼°æŠ¥å‘Š ---")
        quality_report = quality_check(config, final_answer)
        logging.info(quality_report)

    saved_filepath = None
    if save_result:
        filename = output_filename or f"final_solution_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
        session_dir = config.session_dir
        if session_dir and os.path.isdir(session_dir):
            saved_filepath = os.path.join(session_dir, filename)
            try:
                with open(saved_filepath, "w", encoding="utf-8") as f:
                    f.write(final_answer)
                logging.info("ğŸ‰ æœ€ç»ˆæŠ¥å‘Šå·²æˆåŠŸä¿å­˜è‡³: %s", saved_filepath)
            except Exception as exc:
                logging.error("ä¿å­˜æœ€ç»ˆæŠ¥å‘Šæ—¶å‘ç”Ÿé”™è¯¯: %s", exc)
                saved_filepath = None
        else:
            logging.error("ä¼šè¯ç›®å½•ä¸å­˜åœ¨ï¼Œæ— æ³•ä¿å­˜æœ€ç»ˆæ–‡ä»¶ã€‚")

    return WorkflowResult(
        raw_result=raw_result,
        final_answer=final_answer,
        quality_report=quality_report,
        saved_filepath=saved_filepath,
        success=True,
    )
