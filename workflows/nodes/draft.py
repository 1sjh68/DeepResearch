from __future__ import annotations

import logging
import re
from typing import Any, cast

from core.context_manager import ContextManager
from core.progress import StepOutput, step_result, workflow_step
from core.state_manager import WorkflowStateAdapter
from planning.tool_definitions import DraftModel, SectionContent
from utils.id_manager import ensure_section_id
from utils.iteration_storage import archive_iteration_snapshot
from utils.progress_tracker import safe_pulse, safe_step_update
from workflows.graph_state import GraphState
from workflows.nodes.sub_workflows.drafting import (
    generate_section_content,
    generate_section_content_structured,
)
from workflows.prompts import DRAFT_SYSTEM_PROMPT

TOPOLOGY_STEP_NAME = "topology_writer_node"


@workflow_step(TOPOLOGY_STEP_NAME, "æ‹“æ‰‘å†™ä½œåˆç¨¿")
def topology_writer_node(state: GraphState) -> StepOutput:
    workflow_state = WorkflowStateAdapter.ensure(state)

    if workflow_state.draft_content:
        logging.info("æ£€æµ‹åˆ°é¢„å¡«å……çš„è‰ç¨¿å†…å®¹ï¼Œè·³è¿‡åˆç¨¿ç”Ÿæˆã€‚")
        return step_result({}, "è‰ç¨¿å·²å­˜åœ¨")

    config = workflow_state.config
    safe_pulse(
        config.task_id,
        f"è¿­ä»£ 0/{config.max_refinement_rounds} Â· ç”Ÿæˆåˆç¨¿ä¸­...",
    )

    style_guide = workflow_state.style_guide or ""
    outline_data = workflow_state.outline
    if not outline_data:
        raise ValueError("topology_writer_node æ— æ³•ä» state ä¸­è·å– 'outline'ã€‚å·¥ä½œæµå¯èƒ½å·²åœ¨ plan_node ä¸­å¤±è´¥ã€‚")

    skeleton_outline = workflow_state.skeleton_outline or _synthesize_skeleton_from_outline(outline_data)
    skeleton_index = _flatten_skeleton_map(skeleton_outline)
    digest_index = _build_digest_index(workflow_state.section_digests)

    external_data = workflow_state.external_data or ""
    embedding_model = getattr(config, "embedding_model_instance", None)
    context_manager = ContextManager(
        config,
        style_guide,
        outline_data,
        external_data,
        embedding_model,
        repository=workflow_state.context_repository,
        rag_service=workflow_state.rag_service,
        assembler=workflow_state.context_assembler,
    )

    # æ£€æŸ¥æ˜¯å¦å¯ç”¨ç»“æ„åŒ–è¾“å‡º
    use_structured_output = getattr(config, "use_structured_draft_output", False)

    if use_structured_output:
        result_data, detail = _generate_structured_draft(
            workflow_state,
            config,
            outline_data,
            context_manager,
            style_guide,
            external_data,
            skeleton_index,
            digest_index,
        )
    else:
        result_data, detail = _generate_traditional_draft(
            workflow_state,
            config,
            outline_data,
            context_manager,
            style_guide,
            external_data,
            skeleton_index,
            digest_index,
        )

    repository, rag_service, assembler = context_manager.export_components()
    mutable_result = cast(dict[str, Any], result_data)
    mutable_result.update(
        {
            "context_repository": repository,
            "rag_service": rag_service,
            "context_assembler": assembler,
        }
    )
    return step_result(mutable_result, detail)


def _generate_traditional_draft(
    workflow_state,
    config,
    outline_data,
    context_manager,
    style_guide,
    external_data,
    skeleton_index,
    digest_index,
) -> tuple[dict[str, Any], str]:
    """ç”Ÿæˆä¼ ç»Ÿæ–‡æœ¬æ ¼å¼çš„è‰ç¨¿ï¼ˆå‘åå…¼å®¹ï¼‰"""
    assembled_parts = [f"# {outline_data.get('title', 'Untitled Document')}\n\n"]
    chapters_to_generate = outline_data.get("outline", [])
    total_chapters = len(chapters_to_generate) or 1

    for i, chapter in enumerate(chapters_to_generate):
        logging.info(
            "  -> èµ·è‰ç« èŠ‚ %s/%s: %s",
            i + 1,
            len(chapters_to_generate),
            chapter.get("title"),
        )
        safe_step_update(
            config.task_id,
            TOPOLOGY_STEP_NAME,
            (i / total_chapters) * 100.0,
            f"èµ·è‰ç« èŠ‚ {i + 1}/{len(chapters_to_generate)}",
        )
        section_payload = dict(chapter)
        # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨ ensure_section_id ç¡®ä¿ ID è¢«ä¿å­˜
        section_id = ensure_section_id(section_payload)

        skeleton_meta = skeleton_index.get(section_id)
        if skeleton_meta:
            section_payload["must_include"] = skeleton_meta.get("must_include", [])
            section_payload["organization_hint"] = skeleton_meta.get("organization_hint", "")

        digest_points = digest_index.get(section_id, [])
        section_payload["digest_points"] = digest_points

        context_for_chapter = context_manager.get_context_for_standalone_chapter(section_payload.get("title"))
        structured_brief = _compose_section_brief(section_payload, digest_points)
        combined_context = f"{structured_brief}\n\n{context_for_chapter}".strip()

        chapter_content = generate_section_content(
            config,
            section_data=section_payload,
            system_prompt=DRAFT_SYSTEM_PROMPT,
            model_name=config.main_ai_model,
            overall_context=combined_context,
            is_subsection=False,
        )
        assembled_parts.append(chapter_content)
        context_manager.update_completed_chapter_content(section_payload.get("title"), chapter_content)
        safe_step_update(
            config.task_id,
            TOPOLOGY_STEP_NAME,
            ((i + 1) / total_chapters) * 100.0,
            f"å·²å®Œæˆç« èŠ‚ {i + 1}/{len(chapters_to_generate)}",
        )

    draft_content = "".join(assembled_parts)
    archive_iteration_snapshot(config, 0, "initial_draft", draft_content)
    detail = f"ç”Ÿæˆè‰ç¨¿ç« èŠ‚ {len(chapters_to_generate)} ä¸ª"
    return {"draft_content": draft_content}, detail


def _generate_structured_draft(
    workflow_state,
    config,
    outline_data,
    context_manager,
    style_guide,
    external_data,
    skeleton_index,
    digest_index,
) -> tuple[dict[str, Any], str]:
    """ç”Ÿæˆç»“æ„åŒ–æ ¼å¼çš„è‰ç¨¿"""
    logging.info("å¼€å§‹ç”Ÿæˆç»“æ„åŒ–è‰ç¨¿...")

    document_title = outline_data.get("title", "Untitled Document")
    sections = []

    chapters_to_generate = outline_data.get("outline", [])
    total_chapters = len(chapters_to_generate) or 1
    for i, chapter in enumerate(chapters_to_generate):
        logging.info(
            "  -> ç”Ÿæˆç»“æ„åŒ–ç« èŠ‚ %s/%s: %s",
            i + 1,
            len(chapters_to_generate),
            chapter.get("title"),
        )
        safe_step_update(
            config.task_id,
            TOPOLOGY_STEP_NAME,
            (i / total_chapters) * 100.0,
            f"ç”Ÿæˆç»“æ„åŒ–ç« èŠ‚ {i + 1}/{len(chapters_to_generate)}",
        )

        section_payload = dict(chapter)
        # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨ ensure_section_id ç¡®ä¿ ID è¢«ä¿å­˜
        section_id = ensure_section_id(section_payload)

        skeleton_meta = skeleton_index.get(section_id)
        if skeleton_meta:
            section_payload["must_include"] = skeleton_meta.get("must_include", [])
            section_payload["organization_hint"] = skeleton_meta.get("organization_hint", "")

        digest_points = digest_index.get(section_id, [])
        section_payload["digest_points"] = digest_points

        context_for_chapter = context_manager.get_context_for_standalone_chapter(section_payload.get("title"))
        structured_brief = _compose_section_brief(section_payload, digest_points)
        combined_context = f"{structured_brief}\n\n{context_for_chapter}".strip()

        try:
            section_content = generate_section_content_structured(
                config,
                section_data=section_payload,
                system_prompt=DRAFT_SYSTEM_PROMPT,
                model_name=config.main_ai_model,
                overall_context=combined_context,
            )

            if section_content:
                sections.append(section_content)
                context_manager.update_completed_chapter_content(section_payload.get("title"), section_content.content)

        except Exception as e:
            logging.warning(f"ç« èŠ‚ '{chapter.get('title')}' ç»“æ„åŒ–ç”Ÿæˆå¤±è´¥ï¼Œä½¿ç”¨å›é€€æœºåˆ¶: {e}")
            # å›é€€åˆ°ä¼ ç»Ÿç”Ÿæˆæ–¹å¼
            fallback_content = generate_section_content(
                config,
                section_data=section_payload,
                system_prompt=DRAFT_SYSTEM_PROMPT,
                model_name=config.main_ai_model,
                overall_context=combined_context,
                is_subsection=False,
            )

            # å°†ä¼ ç»Ÿå†…å®¹è½¬æ¢ä¸ºç»“æ„åŒ–æ ¼å¼
            key_claims = []
            todos = []

            section_obj = SectionContent(
                section_id=section_id,
                title=section_payload.get("title", f"ç« èŠ‚ {i + 1}"),
                content=fallback_content,
                key_claims=key_claims,
                todos=todos,
                word_count=len(fallback_content) if fallback_content else 0,
            )
            sections.append(section_obj)
        safe_step_update(
            config.task_id,
            TOPOLOGY_STEP_NAME,
            ((i + 1) / total_chapters) * 100.0,
            f"å·²å®Œæˆç»“æ„åŒ–ç« èŠ‚ {i + 1}/{len(chapters_to_generate)}",
        )

    # åˆ›å»ºç»“æ„åŒ–è‰ç¨¿æ¨¡å‹
    total_word_count = sum(section.word_count for section in sections if section.word_count)

    draft_model = DraftModel(
        sections=sections,
        document_title=document_title,
        summary=None,
        total_word_count=total_word_count,
        writing_style_notes=style_guide,
    )

    # å¯¼å‡ºä¸ºä¼ ç»Ÿæ–‡æœ¬æ ¼å¼ä»¥ä¿æŒå…¼å®¹æ€§
    legacy_draft_content = _convert_structured_to_legacy_format(draft_model)
    archive_iteration_snapshot(config, 0, "initial_draft", legacy_draft_content)

    # ä¿å­˜ç»“æ„åŒ–æ•°æ®
    structured_data = {
        "draft_model": draft_model.model_dump(),
        "legacy_content": legacy_draft_content,
    }

    detail = f"ç”Ÿæˆç»“æ„åŒ–è‰ç¨¿ç« èŠ‚ {len(sections)} ä¸ª"
    return {
        "draft_content": legacy_draft_content,
        "draft_structure": structured_data,
    }, detail


def _convert_structured_to_legacy_format(draft_model: DraftModel) -> str:
    """å°†ç»“æ„åŒ–è‰ç¨¿æ¨¡å‹è½¬æ¢ä¸ºä¼ ç»Ÿæ–‡æœ¬æ ¼å¼ï¼ˆç”¨äºå‘åå…¼å®¹ï¼‰"""
    parts: list[str] = []

    if draft_model.document_title:
        parts.append(f"# {draft_model.document_title}\n\n")

    for index, section in enumerate(draft_model.sections):
        parts.append(f"\n## {section.title}\n\n")
        parts.append(section.content)

        # æ·»åŠ å…³é”®ä¸»å¼ åˆ°æ–‡æ¡£ä¸­
        if section.key_claims:
            parts.append("\n\n**å…³é”®ä¸»å¼ ï¼š**\n")
            for claim in section.key_claims:
                parts.append(f"- {claim}\n")

        # æ·»åŠ ä»»åŠ¡åˆ—è¡¨åˆ°æ–‡æ¡£ä¸­
        if section.todos:
            parts.append("\n\n**å¾…åŠä»»åŠ¡ï¼š**\n")
            for todo in section.todos:
                parts.append(f"- {todo}\n")

        parts.append("\n\n")

    return "".join(parts)


# ğŸ”§ ä¿®å¤ï¼šåˆ é™¤æœ¬åœ°çš„ _ensure_section_id å‡½æ•°ï¼Œä½¿ç”¨ utils.id_manager.ensure_section_id


def _compose_section_brief(section_payload: dict[str, Any], digest_points: list[dict[str, str]]) -> str:
    title = section_payload.get("title", "æœªå‘½åç« èŠ‚")
    must_include = section_payload.get("must_include") or []
    organization_hint = section_payload.get("organization_hint", "")
    lines: list[str] = [f"--- Skeleton Checklist Â· {title} ---"]
    if must_include:
        lines.extend([f"- {point}" for point in must_include[:6]])
    if organization_hint:
        lines.append(f"ç»„ç»‡å»ºè®®ï¼š{organization_hint}")

    if digest_points:
        lines.append("--- Indexed Facts (å¼•ç”¨ ref:source#anchor) ---")
        for point in digest_points[:6]:
            fact_text = point.get("fact", "")
            citation = point.get("citation", "ref:pending")
            snippet = fact_text[:220].strip()
            lines.append(f"- {snippet} (ref: {citation})")
    return "\n".join(lines)


def _build_digest_index(section_digests: dict[str, Any] | None) -> dict[str, list[dict[str, str]]]:
    if not section_digests:
        return {}
    mapping: dict[str, list[dict[str, str]]] = {}
    for entry in section_digests.get("sections", []):
        section_id = entry.get("section_id")
        if not section_id:
            continue
        mapping[section_id] = entry.get("facts", [])
    return mapping


def _flatten_skeleton_map(skeleton_outline: dict[str, Any]) -> dict[str, dict[str, Any]]:
    mapping: dict[str, dict[str, Any]] = {}

    def _walk(sections: list[dict[str, Any]]):
        for section in sections:
            # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨ ensure_section_id ç¡®ä¿ ID è¢«ä¿å­˜
            section_id = ensure_section_id(section)
            mapping[section_id] = {
                "must_include": section.get("must_include", []),
                "organization_hint": section.get("organization_hint", ""),
            }
            children = section.get("children") or []
            if children:
                _walk(children)

    _walk(skeleton_outline.get("sections", []))
    return mapping


def _synthesize_skeleton_from_outline(outline_data: dict[str, Any]) -> dict[str, Any]:
    return {
        "title": outline_data.get("title", "Untitled Document"),
        "sections": [_outline_to_skeleton(chapter, depth=0) for chapter in outline_data.get("outline", [])],
    }


def _outline_to_skeleton(chapter: dict[str, Any], depth: int) -> dict[str, Any]:
    # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨ ensure_section_id ç¡®ä¿ ID è¢«ä¿å­˜
    section_id = ensure_section_id(chapter)
    title = chapter.get("title", f"æœªå‘½åç« èŠ‚-{section_id[:8]}")
    return {
        "id": section_id,
        "title": title,
        "must_include": _derive_must_include_points(chapter),
        "organization_hint": _derive_org_hint(chapter, depth),
        "children": [_outline_to_skeleton(child, depth + 1) for child in chapter.get("sections", []) or []],
    }


def _derive_must_include_points(chapter: dict[str, Any]) -> list[str]:
    description = chapter.get("description", "") or ""
    sentences = [frag.strip() for frag in re.split(r"[ã€‚ï¼!ï¼Ÿ?ï¼›;]", description) if frag and len(frag.strip()) >= 6]
    child_titles = [child.get("title", "").strip() for child in chapter.get("sections", []) or [] if child.get("title")]
    child_requirements = [f"è¦†ç›–å­ä¸»é¢˜ï¼š{child_title}" for child_title in child_titles]
    merged = sentences + child_requirements
    if not merged:
        merged = ["è¯´æ˜æœ¬èŠ‚çš„å…³é”®æ¦‚å¿µã€æ•°æ®ä¸å¯¹æ¯”ç»“è®ºã€‚"]
    return merged[:6]


def _derive_org_hint(chapter: dict[str, Any], depth: int) -> str:
    child_titles = [child.get("title", "").strip() for child in chapter.get("sections", []) or [] if child.get("title")]
    if not child_titles:
        return "å›´ç»•â€œèƒŒæ™¯â†’åˆ†æâ†’ç»“è®ºâ€ä¸‰æ®µå±•å¼€ã€‚"
    prefix = "å¶å­å°èŠ‚" if depth >= 1 else "çˆ¶çº§ç« èŠ‚"
    joined = " â†’ ".join(child_titles[:4])
    return f"{prefix}å»ºè®®ä¾æ¬¡é˜è¿°ï¼š{joined}ï¼Œå¹¶åœ¨ç»“å°¾æ€»ç»“å¯¹æ¯”ã€‚"


__all__ = ["topology_writer_node"]
